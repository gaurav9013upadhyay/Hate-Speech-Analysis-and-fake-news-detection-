{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "ewhOFT5b_EiW",
        "outputId": "07539d7e-229a-474f-bc0a-f1f83d48c73a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: anvil-uplink in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Collecting argparse (from anvil-uplink)\n",
            "  Using cached argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (1.17.0)\n",
            "Requirement already satisfied: ws4py-sslupdate in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (0.5.1b0)\n",
            "Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Installing collected packages: argparse\n",
            "Successfully installed argparse-1.4.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "fc6e08d5010d41d1be8a468b0f1cdc20",
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install anvil-uplink\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "963hrcnVlJXW",
        "outputId": "76274f71-3c9d-4dae-8c8f-1114c880bf44"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "dataset=pd.read_csv(\"/content/drive/MyDrive/Twitter_dataSet/labeled_data.csv\")\n",
        "dataset=dataset[\"tweet\"]\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "filtered=[]\n",
        "\n",
        "for i in dataset:\n",
        "    text = i\n",
        "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    filtered.append(filtered_tokens)\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "\n",
        "model_name = \"Hate-speech-CNERG/dehatebert-mono-english\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "def predict_hate_speech(text):\n",
        "\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    softmax = torch.nn.Softmax(dim=1)\n",
        "    probs = softmax(logits)\n",
        "\n",
        "    hate_speech_prob = probs[0][1].item()\n",
        "\n",
        "    if hate_speech_prob > 0.5:\n",
        "        return \"Hate Speech\", hate_speech_prob\n",
        "    else:\n",
        "        return \"Non-Hate Speech\", hate_speech_prob\n",
        "\n",
        "toxicity={}\n",
        "for tweets in filtered[:50]:\n",
        "    for tweet in tweets:\n",
        "        label, probability = predict_hate_speech(tweet)\n",
        "        toxicity[tweet]=label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9I64wecfnbLd",
        "outputId": "0c27f48a-03c9-4454-bcd1-25d08978cfa6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'rt': 'Non-Hate Speech',\n",
              " 'mayasolovely': 'Non-Hate Speech',\n",
              " 'woman': 'Non-Hate Speech',\n",
              " 'shouldnt': 'Non-Hate Speech',\n",
              " 'complain': 'Non-Hate Speech',\n",
              " 'cleaning': 'Non-Hate Speech',\n",
              " 'house': 'Non-Hate Speech',\n",
              " 'amp': 'Non-Hate Speech',\n",
              " 'man': 'Non-Hate Speech',\n",
              " 'always': 'Non-Hate Speech',\n",
              " 'take': 'Non-Hate Speech',\n",
              " 'trash': 'Non-Hate Speech',\n",
              " 'mleew17': 'Non-Hate Speech',\n",
              " 'boy': 'Non-Hate Speech',\n",
              " 'dats': 'Non-Hate Speech',\n",
              " 'coldtyga': 'Non-Hate Speech',\n",
              " 'dwn': 'Non-Hate Speech',\n",
              " 'bad': 'Hate Speech',\n",
              " 'cuffin': 'Non-Hate Speech',\n",
              " 'dat': 'Non-Hate Speech',\n",
              " 'hoe': 'Hate Speech',\n",
              " '1st': 'Non-Hate Speech',\n",
              " 'place': 'Non-Hate Speech',\n",
              " 'urkindofbrand': 'Non-Hate Speech',\n",
              " 'dawg': 'Non-Hate Speech',\n",
              " '80sbaby4life': 'Non-Hate Speech',\n",
              " 'ever': 'Non-Hate Speech',\n",
              " 'fuck': 'Non-Hate Speech',\n",
              " 'bitch': 'Hate Speech',\n",
              " 'start': 'Non-Hate Speech',\n",
              " 'cry': 'Non-Hate Speech',\n",
              " 'confused': 'Non-Hate Speech',\n",
              " 'shit': 'Non-Hate Speech',\n",
              " 'c_g_anderson': 'Non-Hate Speech',\n",
              " 'viva_based': 'Non-Hate Speech',\n",
              " 'look': 'Non-Hate Speech',\n",
              " 'like': 'Non-Hate Speech',\n",
              " 'tranny': 'Non-Hate Speech',\n",
              " 'shenikaroberts': 'Non-Hate Speech',\n",
              " 'hear': 'Non-Hate Speech',\n",
              " 'might': 'Non-Hate Speech',\n",
              " 'true': 'Non-Hate Speech',\n",
              " 'faker': 'Non-Hate Speech',\n",
              " 'told': 'Non-Hate Speech',\n",
              " 'ya': 'Non-Hate Speech',\n",
              " '57361': 'Non-Hate Speech',\n",
              " 't_madison_x': 'Non-Hate Speech',\n",
              " 'blows': 'Non-Hate Speech',\n",
              " 'meclaim': 'Non-Hate Speech',\n",
              " 'faithful': 'Non-Hate Speech',\n",
              " 'somebody': 'Non-Hate Speech',\n",
              " 'still': 'Non-Hate Speech',\n",
              " 'fucking': 'Non-Hate Speech',\n",
              " 'hoes': 'Hate Speech',\n",
              " '128514128514128514': 'Non-Hate Speech',\n",
              " '__brighterdays': 'Non-Hate Speech',\n",
              " 'sit': 'Non-Hate Speech',\n",
              " 'hate': 'Hate Speech',\n",
              " 'another': 'Non-Hate Speech',\n",
              " 'got': 'Non-Hate Speech',\n",
              " 'much': 'Non-Hate Speech',\n",
              " 'going': 'Non-Hate Speech',\n",
              " '8220selfiequeenbri': 'Non-Hate Speech',\n",
              " 'cause': 'Non-Hate Speech',\n",
              " 'im': 'Non-Hate Speech',\n",
              " 'tired': 'Non-Hate Speech',\n",
              " 'big': 'Non-Hate Speech',\n",
              " 'bitches': 'Hate Speech',\n",
              " 'coming': 'Non-Hate Speech',\n",
              " 'us': 'Non-Hate Speech',\n",
              " 'skinny': 'Non-Hate Speech',\n",
              " 'girls8221': 'Non-Hate Speech',\n",
              " 'get': 'Non-Hate Speech',\n",
              " 'back': 'Non-Hate Speech',\n",
              " 'thats': 'Non-Hate Speech',\n",
              " 'rhythmixx_': 'Non-Hate Speech',\n",
              " 'hobbies': 'Non-Hate Speech',\n",
              " 'include': 'Non-Hate Speech',\n",
              " 'fighting': 'Non-Hate Speech',\n",
              " 'mariam': 'Non-Hate Speech',\n",
              " 'keeks': 'Non-Hate Speech',\n",
              " 'curves': 'Non-Hate Speech',\n",
              " 'everyone': 'Non-Hate Speech',\n",
              " 'lol': 'Non-Hate Speech',\n",
              " 'walked': 'Non-Hate Speech',\n",
              " 'conversation': 'Non-Hate Speech',\n",
              " 'smh': 'Non-Hate Speech',\n",
              " 'murda': 'Non-Hate Speech',\n",
              " 'gang': 'Non-Hate Speech',\n",
              " 'land': 'Non-Hate Speech',\n",
              " 'smoke': 'Non-Hate Speech',\n",
              " 'losers': 'Non-Hate Speech',\n",
              " 'yea': 'Non-Hate Speech',\n",
              " 'go': 'Non-Hate Speech',\n",
              " 'ig': 'Non-Hate Speech',\n",
              " 'thing': 'Non-Hate Speech',\n",
              " 'nigga': 'Hate Speech',\n",
              " 'miss': 'Non-Hate Speech',\n",
              " 'plz': 'Non-Hate Speech',\n",
              " 'whatever': 'Non-Hate Speech',\n",
              " 'love': 'Non-Hate Speech',\n",
              " 'cut': 'Non-Hate Speech',\n",
              " 'everyday': 'Non-Hate Speech',\n",
              " 'b': 'Non-Hate Speech',\n",
              " 'black': 'Non-Hate Speech',\n",
              " 'bottle': 'Non-Hate Speech',\n",
              " 'broke': 'Non-Hate Speech',\n",
              " 'cant': 'Non-Hate Speech',\n",
              " 'tell': 'Non-Hate Speech',\n",
              " 'nothing': 'Non-Hate Speech',\n",
              " 'cancel': 'Non-Hate Speech',\n",
              " 'nino': 'Non-Hate Speech',\n",
              " 'see': 'Non-Hate Speech',\n",
              " 'wont': 'Non-Hate Speech',\n",
              " 'change': 'Non-Hate Speech',\n",
              " 'dont': 'Non-Hate Speech',\n",
              " 'even': 'Non-Hate Speech',\n",
              " 'suck': 'Non-Hate Speech',\n",
              " 'dick': 'Hate Speech',\n",
              " 'kermit': 'Non-Hate Speech',\n",
              " 'videos': 'Non-Hate Speech',\n",
              " 'bout': 'Non-Hate Speech',\n",
              " 'tip': 'Non-Hate Speech',\n",
              " 'toeing': 'Non-Hate Speech',\n",
              " 'hardwood': 'Non-Hate Speech',\n",
              " 'floors': 'Non-Hate Speech',\n",
              " '128514': 'Non-Hate Speech',\n",
              " 'httptcocou2wq5l4q': 'Non-Hate Speech',\n",
              " 'pussy': 'Hate Speech',\n",
              " 'lips': 'Non-Hate Speech',\n",
              " 'heaven': 'Non-Hate Speech',\n",
              " 'doors': 'Non-Hate Speech',\n",
              " '128524': 'Non-Hate Speech',\n",
              " 'hitting': 'Non-Hate Speech',\n",
              " 'met': 'Non-Hate Speech',\n",
              " 'ocean': 'Non-Hate Speech',\n",
              " 'dr': 'Non-Hate Speech',\n",
              " 'gave': 'Non-Hate Speech',\n",
              " 'pill': 'Non-Hate Speech',\n",
              " 'need': 'Non-Hate Speech',\n",
              " 'trippy': 'Non-Hate Speech',\n",
              " 'hennessy': 'Non-Hate Speech',\n",
              " 'spend': 'Non-Hate Speech',\n",
              " 'money': 'Non-Hate Speech',\n",
              " 'want': 'Non-Hate Speech',\n",
              " 'business': 'Non-Hate Speech',\n",
              " 'txt': 'Non-Hate Speech',\n",
              " 'old': 'Non-Hate Speech',\n",
              " 'new': 'Non-Hate Speech',\n",
              " 'wetter': 'Non-Hate Speech',\n",
              " 'id': 'Non-Hate Speech',\n",
              " 'say': 'Non-Hate Speech',\n",
              " 'would': 'Non-Hate Speech',\n",
              " 'excited': 'Non-Hate Speech',\n",
              " 'aint': 'Non-Hate Speech',\n",
              " 'murder': 'Non-Hate Speech',\n",
              " 'game': 'Non-Hate Speech',\n",
              " 'shut': 'Hate Speech',\n",
              " 'youre': 'Non-Hate Speech',\n",
              " 'toes': 'Non-Hate Speech',\n",
              " 'done': 'Non-Hate Speech',\n",
              " 'stinks': 'Non-Hate Speech',\n",
              " 'bitter': 'Non-Hate Speech',\n",
              " 'wrap': 'Non-Hate Speech',\n",
              " 'angry': 'Non-Hate Speech',\n",
              " 'bird': 'Non-Hate Speech',\n",
              " 'theres': 'Non-Hate Speech',\n",
              " 'app': 'Non-Hate Speech',\n",
              " 'jus': 'Non-Hate Speech',\n",
              " 'meet': 'Non-Hate Speech',\n",
              " 'son': 'Non-Hate Speech',\n",
              " 'mane': 'Non-Hate Speech',\n",
              " 'ass': 'Hate Speech',\n",
              " 'shots': 'Non-Hate Speech',\n",
              " 'lames': 'Non-Hate Speech',\n",
              " 'crying': 'Non-Hate Speech',\n",
              " 'tears': 'Non-Hate Speech',\n",
              " 'clown': 'Non-Hate Speech',\n",
              " 'snoop': 'Non-Hate Speech',\n",
              " 'said': 'Non-Hate Speech',\n",
              " '94': 'Non-Hate Speech',\n",
              " 'momma': 'Non-Hate Speech',\n",
              " 'cats': 'Non-Hate Speech',\n",
              " 'inside': 'Non-Hate Speech',\n",
              " 'doghouse': 'Non-Hate Speech',\n",
              " 'hated': 'Non-Hate Speech',\n",
              " 'favorite': 'Non-Hate Speech',\n",
              " '2mw': 'Non-Hate Speech',\n",
              " 'sevenone': 'Non-Hate Speech',\n",
              " 'httptcobmdsvmc3rc': 'Non-Hate Speech',\n",
              " 'nice': 'Non-Hate Speech',\n",
              " 'girls': 'Non-Hate Speech',\n",
              " 'make': 'Non-Hate Speech',\n",
              " 'naughty': 'Non-Hate Speech',\n",
              " 'yello': 'Non-Hate Speech',\n",
              " 'real': 'Non-Hate Speech',\n",
              " 'body': 'Non-Hate Speech',\n",
              " 'south': 'Non-Hate Speech',\n",
              " 'chick': 'Non-Hate Speech',\n",
              " 'em': 'Non-Hate Speech',\n",
              " 'thick': 'Non-Hate Speech',\n",
              " 'httptcobzrdl3kf7u': 'Non-Hate Speech',\n",
              " 'pimps': 'Non-Hate Speech',\n",
              " 'future': 'Non-Hate Speech',\n",
              " 'voice': 'Non-Hate Speech',\n",
              " 'post': 'Non-Hate Speech',\n",
              " 'picture': 'Non-Hate Speech',\n",
              " '200': 'Non-Hate Speech',\n",
              " 'likes': 'Non-Hate Speech',\n",
              " 'powerful': 'Non-Hate Speech',\n",
              " 'drug': 'Non-Hate Speech',\n",
              " '128517': 'Non-Hate Speech',\n",
              " 'happyhumpday': 'Non-Hate Speech',\n",
              " 'httptcor8jsymib5b': 'Non-Hate Speech',\n",
              " 'quick': 'Non-Hate Speech',\n",
              " 'piece': 'Non-Hate Speech',\n",
              " 'call': 'Non-Hate Speech',\n",
              " 'drive': 'Non-Hate Speech',\n",
              " 'running': 'Non-Hate Speech',\n",
              " 'round': 'Non-Hate Speech',\n",
              " 'brand': 'Non-Hate Speech',\n",
              " 'fucked': 'Non-Hate Speech',\n",
              " 'worst': 'Non-Hate Speech',\n",
              " 'theyll': 'Non-Hate Speech',\n",
              " 'send': 'Non-Hate Speech',\n",
              " 'guys': 'Non-Hate Speech',\n",
              " 'niggas': 'Hate Speech',\n",
              " 'talk': 'Non-Hate Speech'}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "toxicity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di9JnGRhCrM_"
      },
      "outputs": [],
      "source": [
        "import anvil.server\n",
        "\n",
        "anvil.server.connect(\"server_VRABEAOTS6DZLVDUG3DSLBNZ-5TDTS4DZ3LZMRXAU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTCvoUyNOcuL"
      },
      "outputs": [],
      "source": [
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBXfn13TrKl_"
      },
      "outputs": [],
      "source": [
        "# final code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNAxnH3qCAXb",
        "outputId": "7c36d23c-3e84-452a-b908-5e0d56b11790"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-156a9d1beb70>:93: UserWarning: Glyph 9 (\t) missing from current font.\n",
            "  plt.savefig(image_stream, format=\"png\")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import base64\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import anvil.server\n",
        "\n",
        "# Load the hate speech model and tokenizer\n",
        "model_name = \"Hate-speech-CNERG/dehatebert-mono-english\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def predict_hate_speech(text):\n",
        "    \"\"\"\n",
        "    Function to predict whether a sentence is hate speech or not.\n",
        "    \"\"\"\n",
        "    # Tokenize the input sentence\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "\n",
        "    # Ensure inputs are in dictionary format with 'input_ids' and 'attention_mask'\n",
        "    assert 'input_ids' in inputs and 'attention_mask' in inputs, \\\n",
        "        \"Input should be a dictionary containing 'input_ids' and 'attention_mask'\"\n",
        "\n",
        "    # Predict with the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    softmax = torch.nn.Softmax(dim=1)\n",
        "    probs = softmax(logits)\n",
        "\n",
        "    # Get probabilities for both classes (non-hate and hate)\n",
        "    hate_speech_prob = probs[0][1].item()  # Probability of hate speech\n",
        "    non_hate_prob = probs[0][0].item()  # Probability of non-hate speech\n",
        "\n",
        "    return non_hate_prob, hate_speech_prob\n",
        "\n",
        "def create_detailed_explanation(sentence, hate_prob, non_hate_prob):\n",
        "    \"\"\"\n",
        "    Generates a detailed explanation for why the sentence is classified as hate or non-hate speech.\n",
        "    \"\"\"\n",
        "    explanation = f\"### Analysis of the Sentence: '{sentence}'\\n\\n\"\n",
        "\n",
        "    # Explain classification\n",
        "    if hate_prob > non_hate_prob:\n",
        "        explanation += f\"**Classification**: The sentence is classified as **Hate Speech** because the model predicts a higher probability for hate speech ({hate_prob*100:.2f}%) compared to non-hate speech ({non_hate_prob*100:.2f}%).\\n\\n\"\n",
        "    else:\n",
        "        explanation += f\"**Classification**: The sentence is classified as **Non-Hate Speech** because the model predicts a higher probability for non-hate speech ({non_hate_prob*100:.2f}%) compared to hate speech ({hate_prob*100:.2f}%).\\n\\n\"\n",
        "\n",
        "    # Explain token contributions (simulated reasoning for now)\n",
        "    explanation += \"**Key Observations:**\\n\"\n",
        "    explanation += \"- The model analyzed the sentence at a token level to determine the context and tone of the sentence.\\n\"\n",
        "    explanation += \"- Words associated with aggression, hate, or negativity were given higher importance by the model during classification.\\n\"\n",
        "\n",
        "    # Tone and contextual reasoning\n",
        "    if hate_prob > non_hate_prob:\n",
        "        explanation += \"- The model detected potential signs of aggression or hostility in the language used.\\n\"\n",
        "        explanation += \"- The overall tone of the sentence, as interpreted by the model, indicates harmful or offensive intent.\\n\"\n",
        "    else:\n",
        "        explanation += \"- The model found no significant indicators of hate speech in the sentence.\\n\"\n",
        "        explanation += \"- The language used is either neutral or lacks aggressive tones, which led the model to classify the sentence as non-hate speech.\\n\"\n",
        "\n",
        "    # Confidence Insights\n",
        "    explanation += f\"\\n**Confidence Levels:**\\n\"\n",
        "    explanation += f\"- Probability of Non-Hate Speech: {non_hate_prob*100:.2f}%\\n\"\n",
        "    explanation += f\"- Probability of Hate Speech: {hate_prob*100:.2f}%\\n\"\n",
        "\n",
        "    return explanation\n",
        "\n",
        "def generate_image(sentence, hate_prob, non_hate_prob):\n",
        "    \"\"\"\n",
        "    Generates a bar chart representing the probabilities of hate and non-hate speech.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(8, 5))\n",
        "    categories = [\"Non-Hate\", \"Hate\"]\n",
        "    probabilities = [non_hate_prob, hate_prob]\n",
        "    colors = ['#8A2BE2', '#FF4500']  # Custom colors\n",
        "\n",
        "    bars = plt.bar(categories, probabilities, color=colors, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "    # Add sentence above the histogram\n",
        "    plt.text(0.5, 1.05, f\"Sentence: {sentence}\", ha='center', va='center', transform=ax.transAxes,\n",
        "             fontsize=12, fontweight='bold', bbox=dict(facecolor='white', alpha=0.8, edgecolor='black'))\n",
        "\n",
        "    # Add annotations\n",
        "    for bar, prob in zip(bars, probabilities):\n",
        "        ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.02,\n",
        "                f\"{prob:.3f}\", ha='center', fontsize=12, fontweight='bold')\n",
        "\n",
        "    # Save the plot to an in-memory image\n",
        "    image_stream = BytesIO()\n",
        "    plt.savefig(image_stream, format=\"png\")\n",
        "    image_stream.seek(0)\n",
        "\n",
        "    # Encode image in base64\n",
        "    encoded_image = base64.b64encode(image_stream.read()).decode('utf-8')\n",
        "    return encoded_image\n",
        "\n",
        "def analyze_sentence(sentence):\n",
        "    \"\"\"\n",
        "    Main function to analyze the sentence and return hate speech probabilities, an image, and explanation.\n",
        "    \"\"\"\n",
        "    # Get probabilities of non-hate and hate speech\n",
        "    non_hate_prob, hate_prob = predict_hate_speech(sentence)\n",
        "\n",
        "    # Create a detailed explanation based on the probabilities\n",
        "    explanation = create_detailed_explanation(sentence, hate_prob, non_hate_prob)\n",
        "\n",
        "    # Generate a bar chart image for visualization\n",
        "    encoded_image = generate_image(sentence, hate_prob, non_hate_prob)\n",
        "\n",
        "    return non_hate_prob, hate_prob, encoded_image, explanation\n",
        "\n",
        "# Callable function for Anvil\n",
        "@anvil.server.callable\n",
        "def get_analysis(sentence):\n",
        "    \"\"\"\n",
        "    Callable function that is used to get the analysis of a sentence\n",
        "    when called from the Anvil front-end.\n",
        "    \"\"\"\n",
        "    return analyze_sentence(sentence)\n",
        "\n",
        "# Keep the Anvil server running\n",
        "anvil.server.wait_forever()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_R5Uy1WMe7fK"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# from matplotlib.patches import Rectangle\n",
        "# import torch\n",
        "# from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "# from PIL import Image\n",
        "# import io\n",
        "\n",
        "# # Function to generate the hate speech histogram and save it as an image\n",
        "# def generate_hate_speech_histogram(sentence):\n",
        "#     # Generate the hate speech probabilities\n",
        "#     model_name = \"Hate-speech-CNERG/dehatebert-mono-english\"\n",
        "#     model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "#     tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "#     inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "#     with torch.no_grad():\n",
        "#         outputs = model(**inputs)\n",
        "#     logits = outputs.logits\n",
        "#     softmax = torch.nn.Softmax(dim=1)\n",
        "#     probs = softmax(logits)\n",
        "\n",
        "#     hate_speech_prob = probs[0][1].item()  # Probability of hate speech\n",
        "#     non_hate_prob = probs[0][0].item()  # Probability of non-hate speech\n",
        "\n",
        "#     # Create a histogram plot\n",
        "#     fig, ax = plt.subplots(figsize=(8, 5))\n",
        "#     categories = [\"Non-Hate\", \"Hate\"]\n",
        "#     probabilities = [non_hate_prob, hate_speech_prob]\n",
        "#     colors = ['#8A2BE2', '#FF4500']  # Custom colors\n",
        "\n",
        "#     bars = plt.bar(categories, probabilities, color=colors, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "#     # Add sentence above the histogram\n",
        "#     plt.text(0.5, 1.05, f\"Sentence: {sentence}\", ha='center', va='center', transform=ax.transAxes,\n",
        "#              fontsize=12, fontweight='bold', bbox=dict(facecolor='white', alpha=0.8, edgecolor='black'))\n",
        "\n",
        "#     # Add annotations\n",
        "#     for bar, prob in zip(bars, probabilities):\n",
        "#         ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.02,\n",
        "#                 f\"{prob:.3f}\", ha='center', fontsize=12, fontweight='bold')\n",
        "\n",
        "#     # Set the background color and other aesthetic improvements\n",
        "#     ax.set_facecolor('#F0F8FF')\n",
        "#     ax.spines['top'].set_visible(False)\n",
        "#     ax.spines['right'].set_visible(False)\n",
        "#     ax.spines['left'].set_linewidth(1.5)\n",
        "#     ax.spines['bottom'].set_linewidth(1.5)\n",
        "#     plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "#     plt.xlabel(\"Category\", fontsize=14)\n",
        "#     plt.ylabel(\"Probability\", fontsize=14)\n",
        "#     plt.ylim(0, 1)\n",
        "\n",
        "#     # Save the figure as an image in memory (using BytesIO)\n",
        "#     img_stream = io.BytesIO()\n",
        "#     plt.savefig(img_stream, format='png')\n",
        "#     img_stream.seek(0)\n",
        "#     img = Image.open(img_stream)\n",
        "\n",
        "#     # Save the image file and return it (this will be used in Anvil)\n",
        "#     img.save(\"/content/hate_speech_histogram.png\")\n",
        "\n",
        "#     return \"/content/hate_speech_histogram.png\", non_hate_prob, hate_speech_prob, sentence\n",
        "\n",
        "# # Example usage in Colab\n",
        "# sentence = \"I love programming, but hate when things go wrong!\"\n",
        "# image_path, non_hate_prob, hate_prob, text = generate_hate_speech_histogram(sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFR36mf8CmYQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}